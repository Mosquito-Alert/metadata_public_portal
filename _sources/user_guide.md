<style>
    div.center{
        text-align: center
    }
</style>

# Getting Started

## 1. Access metadata

<div class="center">
  <video width="80%" controls loop autoplay muted>
    <source src="./_static/videos/part1_goto_metadata.webm" type="video/webm">
  </video>
</div>

[Mosquito Alert Data Portal](https://mosquito-alert.github.io/metadata_public_portal/README_ma.html) could be accessed from the [Mosquito Alert webpage](http://www.mosquitoalert.com/). In the main menu, hover over _Open Data_ and chose _Mosquito Alert Data Portal and click on the link of the data portal.

The _Accessibility_ section provides a summary table of the available datasets. The headers of table are:

* Dataset: name of the dataset or data catalog (i.e. collection of datasets)
* Project: name of the project or general label that is useful to group similar datasets
* Description: short description of the dataset
* License: specifies the type of license and the conditions of access (i.e. public or private)
* Example: availability of a code-example for a given dataset
* Format: specifies the dataset file format

This table provides a general overview of the datasets. However, to access to an exhaustive description of a dataset (i.e. metadata), just click on the dataset name of interest. Another way to access metadata is to navigate within the
left-side contents menu. The _metadata table_ of a given dataset attributes are defined by the _Schema.org_ vocabulary. Some attributes (i.e. _distribution_, variableMeasured, _measurementTechnique_ and _creator_) are hidden and should be
expanded to show the contents.

## 2. How to get the data

<div class="center">
  <video width="80%" controls loop autoplay muted>
    <source src="./_static/videos/part2_distribution_zenodo.webm" type="video/webm">
  </video>
</div>

Each dataset has a _distribution_ attribute that provides a list of possibles ways to access the dataset (i.e. _DataDownload_ type). For example, the _reports_ dataset has two different ways of access:

* Distribution from Zenodo cloud (i.e. _zenodo_)
* Distribution from MosquitoAlert GitHub repository (i.e. *mosquitoalert_github*)

Both distributions access to the same dataset, but the download and data file read procedures are slightly different. Note that the _encodingFormat_ of _zenodo_ distribution is `[JSON].ZIP`. This means that the dataset is stored as a set (i.e. [...]) of `.json` files, compressed in one `.zip` file. On the other hand,  *mosquitoalert_github* provides direct download for each `.json` file. Thus, the dataset _reports_ downloaded from _zenodo_ should be decompressed and there
is no way to download only a report for a given year. For this last, the *mosquitoalert_github* distribution could be used instead, since as detailed below it provides a direct download link to a year-chunk data file.

The attribute _contentUrl_ provides the link to a dataset download. In case of the _zenodo_ distribution of the dataset _reports_, this is just a DOI link generated by Zenodo when the dataset was published the first time to the repository. Open this link in a new browser's tab to access the website of Zenodo where the dataset is stored. From here, it is possible to download a given version of the dataset or just the most recent one.

In contrast, the _contentUrl_ of the  mosquitoalert_github* distribution has a slightly different format in comparison with _zenodo_. It is a list of two urls, one for the yearly based _reports_ files and another for a table of language translations. Note that the formatting `{YEAR}` in the first url should be substituted by a string corresponding to the year of interest. For example in _Python_, this substitution could be simply performed as

```python
year = "2015"
url = "https://url_path/all_reports{YEAR}.json".format(YEAR=year)
print(url)
# "https://url_path/all_reports2015.json"
```

The following clip is another example of how to use a _contentUrl_ with `{...}` is the *tigapics_mosquitoalert* dataset from the _tigapics_ catalog (see [DataCatalog structure](tigapics)) if the photo ID is known (see _photos_clean_ dataset).

<div class="center">
  <video width="80%" controls loop autoplay muted>
    <source src="./_static/videos/part6_getTigapics.webm" type="video/webm">
  </video>
</div>

## 3. Dataset variables

<div class="center">
  <video width="80%" controls loop autoplay muted>
    <source src="./_static/videos/part3_measurementVariables.webm" type="video/webm">
  </video>
</div>

Dataset variables are described in the _measurementVariables_ metadata attribute. For each variable, a _description_ and data types (i.e. _qudt:dataType_) are provided. Data types follow the [XML Schema Definition standard](https://www.w3.org/TR/xmlschema11-2/#typesystem). Optionally, units measurement information (i.e. _unitText_ attribute) is also provided for physical quantities.

## 4. Python code-examples

<div class="center">
  <video width="80%" controls loop autoplay muted>
    <source src="./_static/videos/part4_codeExamples.webm" type="video/webm">
  </video>
</div>

*Python* scripts (i.e. jupyter notebooks) gives an example on how to programmatically access and read datasets. The list of available code-examples is provided in the dataset summary table of the _Accessability_ section under the _Example_ header. For a given dataset, for each _distribution_, a code-example is provided. The attribute _workExample_ just gives a relative path to the code-example which is mainly used for website development purposes.

To run all the examples, one need to set-up a _Python_ environment on the local machine (see subsection [Local Python environment](local_env)). However, it is also possible to run the examples relative to a _Public_ datasets on the fly without any local installation of _Python_ since we use [MyBinder](https://mybinder.readthedocs.io/en/latest/introduction.html), an online service for building and sharing reproducible and interactive computational environments (see section [MyBinder online service](mybinder)).

(mybinder)=
### 4.1 MyBinder online service

The **MyBinder** service could be used only for _Public_ dataset access, since for security reasons it does not allow to fetch data from FTP sites and it is not advisable to type passwords into a running Binder session (e.g. access by SSH to another machine). 

To start a Binder session, follow those steps:
 
 1. Start a Binder interactive session: [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/Mosquito-Alert/metadata_public_portal/gh-pages)
    ```{note}
    Sometimes, the server could be busy or down for maintenance, thus one should retry to enter.
    ```
 2. Wait for Binder to start-up (few seconds) or to build the image (few minutes)
 3. Once in the Binder session starts, navigate the left-side menu to the `_sources/notebooks` folder where the code-example files (`.ipynb`) are stored
 4. Open a code-example (e.g. `reports.ipynb`) and chose the *Python kernel*
 5. Execute cell codes in order and edit or modify the code if necessary
    ```{note}
    It is not possible to save edited code in a Binder session, thus if needed export the hole file.
    ```

(local_env)=
### 4.2 Local Python environment 

One way to setup a local Python environment that runs the code-examples is by [Conda](https://docs.conda.io/projects/conda/en/latest/index.html) package and environment manager. **Conda** uses the same configuration file (`environment.yml`) that  **MyBinder** uses, thus both environments are very similar.

1. Install [Miniconda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html)
2. Download the [Data Portal webpage](https://github.com/Mosquito-Alert/metadata_public_portal/archive/refs/heads/gh-pages.zip) from the GitHub repository
3. Build a new _conda_ virtual environment given the `environment.yml` configuration file that can be found in the root directory of the downloaded webpage: 
    ```
    $ conda env create --name ma_data_portal --file environment.yml
    ```
4. Install **Jupyter Lab** to run the code-examples stored in `_sources/notebooks/` folder as notebooks:
    ```
    $ conda install -c conda-forge jupyterlab 
    ``` 
5. Lunch the Jupyter Lab session:
    ```
    $ jupyter lab
    ```
6. Chose the *ma_data_portal kernel* and run the code-examples in `_sources/notebooks`

(tigapics)=
## 5. DataCatalog structure

<div class="center">
  <video width="80%" controls loop autoplay muted>
    <source src="./_static/videos/part5_dataCatalog.webm" type="video/webm">
  </video>
</div>

A data catalog is just a list of datasets described by a _hasPart_ attribute. A catalog allows to avoid metadata redundancy and to group similar datasets together. As an example, the _tigapics_ catalog contains datasets of photos generated by the Mosquito Alert application that have common attributes (i.e. _license_, _citation_, _measurementTechnique_ and _creator_). Only the _temporalCoverage_ and _spatialCoverage_ are specified for each dataset since they may differ. The temporal and spatial coverage attributes given at the head of the data catalog gives a general information about the overall coverage.
